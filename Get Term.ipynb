{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Get Term.ipynb","provenance":[{"file_id":"1J8RUiuBx_P5xjzt3aT0setC7CIZ9MjXy","timestamp":1621207037180}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bryNRbufSxH","executionInfo":{"status":"ok","timestamp":1621234311857,"user_tz":-420,"elapsed":22757,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}},"outputId":"c22ccfe0-9459-43e3-a9f6-a3553cab4703"},"source":["#skip warning\n","import warnings\n","warnings.filterwarnings('ignore')\n","#connect to drive\n","from google.colab import drive  \n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJ1tlE6SfjuC","executionInfo":{"status":"ok","timestamp":1621234383338,"user_tz":-420,"elapsed":69336,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}},"outputId":"7d7010c1-2113-4d69-c87e-3d48f4a3c766"},"source":["!pip install PyMuPDF #package to read pdf\n","!pip install nltk==3.4 #package to preprocessing text\n","import nltk \n","nltk.download(\"all\") #download all tools in nltk"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting PyMuPDF\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/e8/bfd971ed4515fcdc0f7eec374a515f4608b141c62a0fb6949ad8425fb80b/PyMuPDF-1.18.13-cp37-cp37m-manylinux2010_x86_64.whl (6.4MB)\n","\u001b[K     |████████████████████████████████| 6.4MB 6.9MB/s \n","\u001b[?25hInstalling collected packages: PyMuPDF\n","Successfully installed PyMuPDF-1.18.13\n","Collecting nltk==3.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4) (1.15.0)\n","Collecting singledispatch\n","  Downloading https://files.pythonhosted.org/packages/7a/12/2b10635e91ec4007e2a287812b1a1c8649cf68686ff2d69ed97553cf8a7a/singledispatch-3.6.1-py2.py3-none-any.whl\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4-cp37-none-any.whl size=1436385 sha256=9fb9df9bd106fb7bd607ec1619d029292ee8789795ca3ec41fe333abdcff5f93\n","  Stored in directory: /root/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e\n","Successfully built nltk\n","Installing collected packages: singledispatch, nltk\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed nltk-3.4 singledispatch-3.6.1\n"],"name":"stdout"},{"output_type":"stream","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/omw.zip.\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet.zip.\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"MI84q8XcfsLc","executionInfo":{"status":"ok","timestamp":1621234383339,"user_tz":-420,"elapsed":67492,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}}},"source":["import numpy as np #math and matrix processing\n","import pandas as pd #csv/dataframe processing\n","import fitz #lib to read pdf(pyMUPDF)\n","import re #regex lib\n","from nltk.tokenize import sent_tokenize #tokenisasi kalimat\n","from nltk.tokenize import word_tokenize #memisahkan antar kata\n","from nltk import ngrams #pembentuk token\n","from nltk.corpus import stopwords #penghapus kata tidak penting"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"uno8rHWggZfk","executionInfo":{"status":"ok","timestamp":1621234884957,"user_tz":-420,"elapsed":838,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}}},"source":["list_pdf = pd.read_csv('/content/drive/MyDrive/Skripsi_Putri/DataEmiten_2018.csv') #baca nama-nama perusahaan\n","sektor = 'IDXPROPERT' #set sektor\n","tahun = '2018'"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-jCT86bgcQJ","executionInfo":{"status":"ok","timestamp":1621234884957,"user_tz":-420,"elapsed":834,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}}},"source":["#fungsi baca pdf\n","def get_dataset(sektor,pdfs) :\n","  docs = []\n","  list_file = []\n","  list_companies = pdfs[pdfs[\"Sektor\"] == sektor]\n","  for code in list_companies['Code'] :\n","    pdf_path = \"/content/drive/MyDrive/Skripsi_Putri/Annual Report Perusahaan/%s_%s/%s_%s.pdf\"%(sektor,tahun,code,tahun)\n","    try :\n","      doc = fitz.open(pdf_path)\n","    except :\n","      print(\"%s failed to extract\"%code)\n","      continue\n","    num_of_pages = doc.pageCount\n","    print(\"Extract %s.pdf, num_of_page = %s\"%(code,num_of_pages))\n","    text = doc.loadPage(0).getText('text')\n","    for j in range(1,num_of_pages) :\n","      page = doc.loadPage(j) \n","      text_temp = page.getText(\"text\")\n","      text = text + '. ' + text_temp\n","    docs.append(text)\n","    print(\"Extract %s.pdf is finished\"%(code))\n","    list_file.append(code)\n","  return docs,list_file"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"9tEHrXSuhdmz","executionInfo":{"status":"ok","timestamp":1621234884958,"user_tz":-420,"elapsed":832,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}}},"source":["#fungsi cleaning text\n","def data_clean(dataset) :\n","  docs = dataset.copy() # dicopy biar tidak menimpa satu sama lain\n","  result = []\n","  for data in docs :\n","    data = re.sub('\\n', ' ', data) #ganti newline dengan spasi (textnya tidak newline)\n","    data = data.replace('&','and') #ganti semua & dengan and\n","    data = data.replace('/',' or ') #ganti semua / dengan or\n","    data = re.sub('[^a-zA-Z0-9.]',' ',data) #hapus non-alfanumerik selain titik\n","    data = re.sub(' +', ' ', data) #hapus spasi berlebih\n","    data = data.replace(' .','.') #hapus spasi yang setelahnya ada titik. (makan . -> makan.)\n","    data = re.sub('\\.+','.',data) #hapus titik berlebih\n","    data = data.lower() #mengubah semua huruf jadi lowercase\n","    result.append(data) #hasil cleaning\n","  return result\n","\n","#fungsi tokenisasi\n","def sentence_tokenize(dataset) :  \n","  docs = dataset.copy() \n","  result = []\n","  for data in docs :\n","    sentences = sent_tokenize(data) #proses memisahkan antar kalimat\n","    result.append(sentences) #hasil pemisahaan\n","  return result\n","\n","#pembentuk token\n","def ngram(dataset,n) : # n : banyaknya kata dalam satu token\n","  docs = dataset.copy()\n","  result = []\n","  for sentences in docs :\n","    token = []\n","    for sent in sentences :\n","      tokenize = word_tokenize(sent) #proses tokenisasi\n","      filtered_sentence = []  \n","      nltk_stop_words = set(stopwords.words(\"english\"))\n","      for w in tokenize:  \n","        if w not in nltk_stop_words: #hapus kata yang tidak begitu penitng\n","          filtered_sentence.append(w)\n","     \n","      #menbetuk token\n","      gram = list(ngrams(filtered_sentence, n))\n","      gram = [' '.join(token) for token in gram]\n","      token += gram  \n","    result.append(token) #simpan\n","  return result\n","\n","#membersihkan ulang hasil tokenisasi\n","def token_clean(dataset) :\n","  docs = dataset.copy()\n","  result = []\n","  for tokens in docs :\n","    for i in range(len(tokens)) :\n","      tokens[i] = re.sub('\\.|\\. | \\.',\"\",tokens[i]) #menghapus titik, titik kemudian ada spasi, spasi kemudian ada titik\n","    result.append(tokens) #save\n","  return result\n","\n","#clean dan gabungkan unigram, bigram dan trigram\n","def clean_join(uni,bi,tri) :\n","  #pembersihan token\n","  uni = token_clean(uni)\n","  bi = token_clean(bi)\n","  tri = token_clean(tri)\n","\n","  #hapus non-alfabet token. contoh : Rp10 million\n","  for i in range(len(uni)) :\n","    uni[i] = [word for word in uni[i] if word.replace(' ','').isalpha()]\n","  for i in range(len(bi)) :\n","    bi[i] = [word for word in bi[i] if word.replace(' ','').isalpha()]\n","  for i in range(len(tri)) :\n","    tri[i] = [word for word in tri[i] if word.replace(' ','').isalpha()]\n","\n","  #menggabungkan unigram, bigram, dan trigram\n","  all_token = []\n","  num_of_docs = len(files)\n","  for i in range(num_of_docs) :\n","    all_token.append(bi[i]+uni[i]+tri[i])\n","  return all_token"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DcTYqsTeiH1S","executionInfo":{"status":"ok","timestamp":1621235025558,"user_tz":-420,"elapsed":141429,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}},"outputId":"8e90f644-fb29-4130-954d-376c66a84714"},"source":["dataset,files = get_dataset(sektor, list_pdf) #baca pdf \n","print(\"list_files =\",files) #cetak list pdf yang terbaca"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Extract APLN.pdf, num_of_page = 381\n","Extract APLN.pdf is finished\n","Extract ARMY.pdf, num_of_page = 149\n","Extract ARMY.pdf is finished\n","Extract ASRI.pdf, num_of_page = 266\n","Extract ASRI.pdf is finished\n","Extract BCIP.pdf, num_of_page = 129\n","Extract BCIP.pdf is finished\n","Extract BEST.pdf, num_of_page = 157\n","Extract BEST.pdf is finished\n","Extract BIKA.pdf, num_of_page = 265\n","Extract BIKA.pdf is finished\n","Extract BIPP.pdf, num_of_page = 196\n","Extract BIPP.pdf is finished\n","Extract BKDP.pdf, num_of_page = 24\n","Extract BKDP.pdf is finished\n","Extract BKSL.pdf, num_of_page = 237\n","Extract BKSL.pdf is finished\n","Extract BSDE.pdf, num_of_page = 348\n","Extract BSDE.pdf is finished\n","Extract CITY.pdf, num_of_page = 145\n","Extract CITY.pdf is finished\n","Extract COWL.pdf, num_of_page = 151\n","Extract COWL.pdf is finished\n","Extract CPRI.pdf, num_of_page = 64\n","Extract CPRI.pdf is finished\n","Extract CSIS.pdf, num_of_page = 177\n","Extract CSIS.pdf is finished\n","Extract CTRA.pdf, num_of_page = 354\n","Extract CTRA.pdf is finished\n","Extract CTRR.pdf, num_of_page = 276\n","Extract CTRR.pdf is finished\n","Extract DART.pdf, num_of_page = 212\n","Extract DART.pdf is finished\n","Extract DILD.pdf, num_of_page = 406\n","Extract DILD.pdf is finished\n","Extract DMAS.pdf, num_of_page = 238\n","Extract DMAS.pdf is finished\n","Extract DUTI.pdf, num_of_page = 430\n","Extract DUTI.pdf is finished\n","Extract ELTY.pdf, num_of_page = 448\n","Extract ELTY.pdf is finished\n","Extract EMDE.pdf, num_of_page = 360\n","Extract EMDE.pdf is finished\n","Extract FMII.pdf, num_of_page = 114\n","Extract FMII.pdf is finished\n","Extract FORZ.pdf, num_of_page = 88\n","Extract FORZ.pdf is finished\n","Extract GAMA.pdf, num_of_page = 106\n","Extract GAMA.pdf is finished\n","Extract GMTD.pdf, num_of_page = 330\n","Extract GMTD.pdf is finished\n","Extract GPRA.pdf, num_of_page = 298\n","Extract GPRA.pdf is finished\n","Extract GWSA.pdf, num_of_page = 238\n","Extract GWSA.pdf is finished\n","Extract INPP.pdf, num_of_page = 256\n","Extract INPP.pdf is finished\n","Extract JRPT.pdf, num_of_page = 234\n","Extract JRPT.pdf is finished\n","Extract KIJA.pdf, num_of_page = 270\n","Extract KIJA.pdf is finished\n","Extract LAND.pdf, num_of_page = 194\n","Extract LAND.pdf is finished\n","Extract LCGP.pdf, num_of_page = 115\n","Extract LCGP.pdf is finished\n","Extract LPCK.pdf, num_of_page = 378\n","Extract LPCK.pdf is finished\n","Extract LPKR.pdf, num_of_page = 538\n","Extract LPKR.pdf is finished\n","Extract LPLI.pdf, num_of_page = 266\n","Extract LPLI.pdf is finished\n","Extract MDLN.pdf, num_of_page = 397\n","Extract MDLN.pdf is finished\n","Extract MPRO.pdf, num_of_page = 179\n","Extract MPRO.pdf is finished\n","Extract MTLA.pdf, num_of_page = 450\n","Extract MTLA.pdf is finished\n","Extract MTSM.pdf, num_of_page = 119\n","Extract MTSM.pdf is finished\n","Extract MYRX.pdf, num_of_page = 205\n","Extract MYRX.pdf is finished\n","Extract NIRO.pdf, num_of_page = 286\n","Extract NIRO.pdf is finished\n","Extract OMRE.pdf, num_of_page = 147\n","Extract OMRE.pdf is finished\n","Extract PLIN.pdf, num_of_page = 280\n","Extract PLIN.pdf is finished\n","Extract POLI.pdf, num_of_page = 230\n","Extract POLI.pdf is finished\n","Extract POLL.pdf, num_of_page = 253\n","Extract POLL.pdf is finished\n","Extract PPRO.pdf, num_of_page = 896\n","Extract PPRO.pdf is finished\n","Extract PTHK.pdf, num_of_page = 651\n","Extract PTHK.pdf is finished\n","Extract PUDP.pdf, num_of_page = 58\n","Extract PUDP.pdf is finished\n","Extract PWON.pdf, num_of_page = 218\n","Extract PWON.pdf is finished\n","Extract RBMS.pdf, num_of_page = 261\n","Extract RBMS.pdf is finished\n","Extract RDTX.pdf, num_of_page = 178\n","Extract RDTX.pdf is finished\n","Extract RIMO.pdf, num_of_page = 192\n","Extract RIMO.pdf is finished\n","Extract RODA.pdf, num_of_page = 195\n","Extract RODA.pdf is finished\n","Extract SATU.pdf, num_of_page = 187\n","Extract SATU.pdf is finished\n","Extract SCBD.pdf, num_of_page = 214\n","Extract SCBD.pdf is finished\n","Extract SMDM.pdf, num_of_page = 187\n","Extract SMDM.pdf is finished\n"],"name":"stdout"},{"output_type":"stream","text":["mupdf: object out of range (1126 0 R); xref size 1126\n","mupdf: object out of range (1126 0 R); xref size 1126\n","mupdf: object out of range (1127 0 R); xref size 1126\n","mupdf: object out of range (1127 0 R); xref size 1126\n"],"name":"stderr"},{"output_type":"stream","text":["Extract SMRA.pdf, num_of_page = 313\n","Extract SMRA.pdf is finished\n","Extract TARA.pdf, num_of_page = 168\n","Extract TARA.pdf is finished\n","Extract URBN.pdf, num_of_page = 204\n","Extract URBN.pdf is finished\n","list_files = ['APLN', 'ARMY', 'ASRI', 'BCIP', 'BEST', 'BIKA', 'BIPP', 'BKDP', 'BKSL', 'BSDE', 'CITY', 'COWL', 'CPRI', 'CSIS', 'CTRA', 'CTRR', 'DART', 'DILD', 'DMAS', 'DUTI', 'ELTY', 'EMDE', 'FMII', 'FORZ', 'GAMA', 'GMTD', 'GPRA', 'GWSA', 'INPP', 'JRPT', 'KIJA', 'LAND', 'LCGP', 'LPCK', 'LPKR', 'LPLI', 'MDLN', 'MPRO', 'MTLA', 'MTSM', 'MYRX', 'NIRO', 'OMRE', 'PLIN', 'POLI', 'POLL', 'PPRO', 'PTHK', 'PUDP', 'PWON', 'RBMS', 'RDTX', 'RIMO', 'RODA', 'SATU', 'SCBD', 'SMDM', 'SMRA', 'TARA', 'URBN']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rH3BXzLnid8z","executionInfo":{"status":"ok","timestamp":1621235042631,"user_tz":-420,"elapsed":158498,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}}},"source":["dataset2 = data_clean(dataset) #clean text\n","dataset2 = sentence_tokenize(dataset2) #pemisah antar kalimat"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"45xkse-sivdc","executionInfo":{"status":"ok","timestamp":1621234878286,"user_tz":-420,"elapsed":59549,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}}},"source":["token_unigram = ngram(dataset2,1) #pembentuk token 1 word\n","token_bigram = ngram(dataset2,2) #pembentuk token 2 word\n","token_trigram = ngram(dataset2,3) #pembentuk token 3 word"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"CP7v6UJcjSwt","executionInfo":{"status":"ok","timestamp":1621234882569,"user_tz":-420,"elapsed":63346,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}}},"source":["pdf_tokens = clean_join(token_unigram,token_bigram,token_trigram) #membersihkan dan menggabungkan token"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWxrgKrMkMon","executionInfo":{"status":"ok","timestamp":1621234884104,"user_tz":-420,"elapsed":64383,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}}},"source":["#save token to drive per sektor\n","import json\n","save_tokens = dict()\n","for i in range(len(pdf_tokens)) :\n","  save_tokens[files[i]] = pdf_tokens[i]\n","with open('/content/drive/MyDrive/Skripsi_Putri/Hasil/Tokens/'+sektor+'_'+tahun+'.json', 'w') as fp:\n","  json.dump(save_tokens, fp)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"g0mWlQyA2o4h","executionInfo":{"status":"ok","timestamp":1621235042631,"user_tz":-420,"elapsed":158496,"user":{"displayName":"Andika Rahim Darusalam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggshpv3c_ssUaoZlM7PSTLM21xotPq_pt_-yfhp=s64","userId":"17518320789229734134"}}},"source":[""],"execution_count":26,"outputs":[]}]}